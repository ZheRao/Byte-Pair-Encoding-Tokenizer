{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from typing import Optional\n",
    "\n",
    "class ConfigError(Exception):\n",
    "    \"\"\"for invalid user configuration of tokenizer class\"\"\"\n",
    "    pass\n",
    "\n",
    "class BaseBPETokenizer:\n",
    "    \n",
    "    \"\"\"\n",
    "        This class implements byte-pair encoding tokenization\n",
    "        It includes:\n",
    "            1. training tokenization - compress given token sequence based on the byte-pair encoding algorithm, - use child class\n",
    "                details at https://en.wikipedia.org/wiki/Byte_pair_encoding#:~:text=Byte%20pair%20encoding%20(also%20known,for%20use%20in%20downstream%20modeling.\n",
    "            2. provide encode and decode functions\n",
    "            3. abilities to update or retrain tokenization based on given text \n",
    "            4. save the dictionaries to a directory and named after a unique name given based on the text training one\n",
    "        \n",
    "        Args:\n",
    "            mode: str, takes value of \"train\" or \"infer\" - train allows training a tokenizer from scratch or keep training a tokenizer (must use the same text, this is when user wishes to increase the vocab_size)\n",
    "            text: str, actual text or None if user uses inference mode only\n",
    "            title: str, name of the text file user wishes to train the tokenizer on - will be used to name the vocab_dict and merge_history\n",
    "            retrain: bool, whether to retrain the tokenizer, default = False\n",
    "\n",
    "        Folder/Title Naming Convention:\n",
    "            \"book_title_tok_folder\" - all lower case, connected with underscore\n",
    "        \n",
    "        Dictionary File Naming Convetion:\n",
    "            \"book_title_vocab_dict.pkl\"\n",
    "            \"book_title_merge_history.pkl\"\n",
    "    \"\"\"  \n",
    "\n",
    "    def __init__(self,text:Optional[str], title:str, mode:str = \"infer\",retrain:bool = False):\n",
    "        if mode not in [\"train\",\"infer\"]: raise ConfigError(\"Entered invalid mode, must be one of 'train' or 'infer'\")\n",
    "        self.mode = mode\n",
    "        self.title = title\n",
    "        self.retrain = retrain\n",
    "        if (text is None and mode == \"train\"): raise ConfigError(\"Text not provided for training\")\n",
    "        self._inspect_dict_folder()\n",
    "        # additional initialization for training mode\n",
    "        if self.mode == \"train\": \n",
    "            self._base_vocab = {i: bytes([i]) for i in range(256)}\n",
    "            self._init_tokens = list(text.encode(\"utf-8\"))\n",
    "\n",
    "    def _create_folder(self,folder_name):\n",
    "        \"\"\"create folder for dictionaries after training tokenizer\"\"\"\n",
    "        if os.path.exists(folder_name): shutil.rmtree(folder_name)\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    \n",
    "    def _inspect_dict_folder(self):\n",
    "        \"\"\" \n",
    "            if mode = \"infer\", folder must exist or raise an error\n",
    "            if mode = \"train\", create folder if (not exist or retrain=True)\n",
    "        \"\"\"\n",
    "        folder = self.title + \"_tok_folder\"\n",
    "        file1 = os.path.join(folder,self.title+\"_vocab_dict.pkl\")\n",
    "        file2 = os.path.join(folder,self.title+\"_merge_history.pkl\")\n",
    "        exist = (os.path.exists(file1) and os.path.exists(file2))\n",
    "        if exist:\n",
    "            if self.retrain:\n",
    "                os.remove(file1)\n",
    "                os.remove(file2)\n",
    "        else:\n",
    "            if self.mode == \"infer\": raise FileNotFoundError(f\"cannot find tokenization trained with text from {self.title}\")\n",
    "            else: self._create_folder(folder)\n",
    "    \n",
    "    def _get_pair_counts(self,tokens):\n",
    "        \"\"\"\n",
    "            treverse through the entire encoded text, produce a dictionary with paired occurrences of adjacent tokens\n",
    "                key: token pairs, e.g., (106, 32)\n",
    "                value: counts of occurrence of key, e.g., 300\n",
    "                meaning: token pair (106, 32) occurred 300 times in the text\n",
    "        \"\"\"\n",
    "        count_dict = {}\n",
    "        for (c1, c2) in zip(tokens[:-1], tokens[1:]):\n",
    "            count_dict[(c1,c2)] = count_dict.get((c1,c2),0) + 1\n",
    "        return count_dict\n",
    "    \n",
    "    def _merge_top_pair(self, old_tokens, pair, new_token):\n",
    "        \"\"\"\n",
    "            merge a token pair into a new token\n",
    "        \"\"\"\n",
    "        new_tokens = []\n",
    "        i = 0\n",
    "        while i < len(old_tokens):\n",
    "            if i < len(old_tokens)-1 and (old_tokens[i], old_tokens[i+1]) == pair:\n",
    "                new_tokens.append(new_token)\n",
    "                i += 2\n",
    "            else:\n",
    "                new_tokens.append(old_tokens[i])\n",
    "                i += 1\n",
    "        return new_tokens\n",
    "\n",
    "    def _call_subclass(self):\n",
    "        if self.mode == \"train\": return BaseBPETokenizerTrain()\n",
    "        else: return BaseBPETokenizerInfer() \n",
    "\n",
    "class BaseBPETokenizerTrain(BaseBPETokenizer):\n",
    "    pass\n",
    "\n",
    "class BaseBPETokenizerInfer(BaseBPETokenizer):\n",
    "    pass\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class parent:\n",
    "    def __init__(self,mode,number):\n",
    "        self.mode = mode\n",
    "        self.number = number\n",
    "        self.operation = \"addition\"\n",
    "\n",
    "    def _print_status(self):\n",
    "        print(f\"I am {self.mode}ing\")\n",
    "\n",
    "\n",
    "class trainclass(parent):\n",
    "    def __init__(self,mode,number):\n",
    "        super(trainclass,self).__init__(mode,number)\n",
    "        self.number2 = self.number * 10\n",
    "        self.sub_mode = mode\n",
    "    def __str__(self):\n",
    "        return f\"I am in train subclass and im with {self.sub_mode} mode\"\n",
    "    \n",
    "class inferclass(parent):\n",
    "    def __init__(self,mode):\n",
    "        super().__init__()\n",
    "        self.number2 = self.number * 20\n",
    "        self.sub_mode = mode\n",
    "    def __str__(self):\n",
    "        return f\"I am in infer subclass and im with {self.sub_mode} mode\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = trainclass(\"train\",30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am training\n"
     ]
    }
   ],
   "source": [
    "a._print_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am in train subclass and im with train mode'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.number2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
