{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from typing import Optional\n",
    "\n",
    "class base_bpe_tokenizer:\n",
    "    \n",
    "    \"\"\"\n",
    "        This class implements byte-pair encoding tokenization\n",
    "        It includes:\n",
    "            1. training tokenization - compress given token sequence based on the byte-pair encoding algorithm, - use child class\n",
    "                details at https://en.wikipedia.org/wiki/Byte_pair_encoding#:~:text=Byte%20pair%20encoding%20(also%20known,for%20use%20in%20downstream%20modeling.\n",
    "            2. provide encode and decode functions\n",
    "            3. abilities to update or retrain tokenization based on given text \n",
    "            4. save the dictionaries to a directory and named after a unique name given based on the text training one\n",
    "        \n",
    "        Args:\n",
    "            mode: str, takes value of \"train\" or \"infer\" - train allows training a tokenizer from scratch or keep training a tokenizer (must use the same text, this is when user wishes to increase the vocab_size)\n",
    "            text: str, actual text or None if user uses inference mode only\n",
    "            title: str, name of the text file user wishes to train the tokenizer on - will be used to name the vocab_dict and merge_history\n",
    "            retrain: bool, whether to retrain the tokenizer, default = False\n",
    "\n",
    "        Folder/Title Naming Convention:\n",
    "            \"book_title_tok_folder\" - all lower case, connected with underscore\n",
    "        \n",
    "        Dictionary File Naming Convetion:\n",
    "            \"book_title_vocab_dict.pkl\"\n",
    "            \"book_title_merge_history.pkl\"\n",
    "    \"\"\"  \n",
    "\n",
    "    def __init__(self,text:Optional[str], title:str, mode:str = \"infer\",retrain:bool = False):\n",
    "        self.mode = mode\n",
    "        self.title = title\n",
    "        self.text = text\n",
    "        self.retrain = retrain\n",
    "        self._inspect_dict_folder()\n",
    "    \n",
    "    def _inspect_dict_folder(self):\n",
    "        \"\"\" \n",
    "            if mode = \"infer\", folder must exist or raise an error\n",
    "            if mode = \"train\", create folder if (not exist or retrain=True)\n",
    "        \"\"\"\n",
    "        folder = self.title + \"_tok_folder\"\n",
    "        file1 = os.path.join(folder,self.title+\"_vocab_dict.pkl\")\n",
    "        file2 = os.path.join(folder,self.title+\"_merge_history.pkl\")\n",
    "        exist = (os.path.exists(file1) and os.path.exists(file2))\n",
    "        if exist:\n",
    "            if self.retrain:\n",
    "                os.remove(file1)\n",
    "                os.remove(file2)\n",
    "        else:\n",
    "            if self.mode == \"infer\": raise FileNotFoundError(f\"cannot find tokenization trained with text from {self.title}\")\n",
    "            else:\n",
    "                if os.path.exists(folder): shutil.rmtree(folder)\n",
    "                os.makedirs(folder)\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
